{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Content:**\n",
    "1. Keras layers (input, dense and output)\n",
    "2. Keras model (build, compile, visualize, save)\n",
    "3. Fit/train and evaluate/test the model\n",
    "4. Questions (unanswered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Keras layers (input and dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layers and Tensors:**\n",
    "\n",
    "Layers are used to construct a deep learning model, and tensors are used to define the dataflow through the model.\n",
    "\n",
    "**Input layers**\n",
    "\n",
    "- The first step in creating a neural network model is to define the Input layer. \n",
    "- This layer takes in raw data, usually in the form of numpy arrays. \n",
    "- The shape of the Input layer defines how many variables our neural network will use. For example, if the input data has 10 columns, define an Input layer with a shape of (10,)\n",
    "- input layer allows model to laod data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Input from keras.layers\n",
    "from keras.layers import Input\n",
    "\n",
    "# Create an input layer of shape 1\n",
    "input_tensor = Input(shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# input is a tensor, check type\n",
    "print(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Dense layers** \n",
    "\n",
    "- Once you have an Input layer, the next step is to add a Dense layer.\n",
    "- Dense layers learn a weight matrix, where the first dimension of the matrix is the dimension of the input data, and the second dimension is the dimension of the output data. In above example Input layer has a shape of 1. In this case, output layer will also have a shape of 1. This means that the Dense layer will learn a 1x1 weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load layers\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "# Input layer\n",
    "input_tensor = Input(shape=(1,))\n",
    "\n",
    "# Dense layer\n",
    "output_layer = Dense(1)\n",
    "\n",
    "# Connect the dense layer to the input_tensor\n",
    "output_tensor = output_layer(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# output is a tensor, check type\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output layers**\n",
    "\n",
    "- Output layers are simply Dense layers.\n",
    "- Output layers are used to reduce the dimension of the inputs to the dimension of the outputs. \n",
    "- The output layer allows model to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load layers\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "# Input layer\n",
    "input_tensor = Input(shape=(1,))\n",
    "\n",
    "# Create a dense layer and connect the dense layer to the input_tensor in one step\n",
    "# We did this in 2 steps in above code, but we are doing it in one step now\n",
    "output_tensor = Dense(1)(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x000000000E606C18>\n"
     ]
    }
   ],
   "source": [
    "# layer is a keras object\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a model**\n",
    "\n",
    "- Once you've defined an input layer and an output layer, you can build a Keras model. \n",
    "- The model object is how you tell Keras where the model starts and stops: where data comes in and where predictions come out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input/dense/output layers\n",
    "from keras.layers import Input, Dense\n",
    "input_tensor = Input(shape=(1,))\n",
    "output_tensor = Dense(1)(input_tensor)\n",
    "\n",
    "# Build the model\n",
    "from keras.models import Model\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "# Above model is a complete neural network, ready to learn from data and make prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile a model**\n",
    "\n",
    "- The final step in creating a model is compiling it. Now that we've created a model, we have to compile it before we can fit it to data. This finalizes your model, freezes all its settings, and prepares it to meet some data.\n",
    "\n",
    "- During compilation, we specify the optimizer to use for fitting the model to the data, and a loss function. 'adam' is a good default optimizer to use, and most of the time works well.\n",
    "\n",
    "1. Choose the optimizer which will choose the learning rate [adam is the famous and efficient one]\n",
    "    - Optimizers: GD, SGD, Rmsprop, Nesterov accelerated gradient (NAG), AdaDelta, AdaGrad, Adam \n",
    "2. adam(Adaptive Moment Estimation) adjuts the learning rate as it does gradient decent\n",
    "3. Loss function: Loss function depends on the problem at hand. Mean squared error is a common loss function and will optimize for predicting the mean, as is done in least squares regression. Mean absolute error optimizes for the median and is used in quantile regression. For classification use binary_crossentropy [2 class] or categorical_crossentropy [multiclass]\n",
    "\n",
    "** compile **\n",
    "- Definition : compile(optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize a model**\n",
    "\n",
    "- Now that you've compiled the model, take a look a the result. You can do this by looking at the model summary, as well as its plot.\n",
    "- The summary will tell you the names of the layers, as well as how many units they have and how many parameters are in the model.\n",
    "- The plot will show how the layers connect to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import the plotting function\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n",
    "\n",
    "# Plot the model\n",
    "#plot_model(model, to_file='model.png')\n",
    "\n",
    "# Display the image\n",
    "#data = plt.imread('model.png')\n",
    "#plt.imshow(data)\n",
    "#plt.show()\n",
    "\n",
    "## to see the graph you have to install pydot and graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit and Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Fit and evaluate the model**\n",
    "\n",
    "- Syntax for fitting the model: mode.fit(feature, target, batch size, validation split, verbose)\n",
    "\n",
    "    - feature: a numpy matrix with which are best correlated with the target\n",
    "    - target: the item you want to predict\n",
    "    - batch size: how many rows of data are used for each step of stochastic gradient descent\n",
    "    - validation split: tell keras to use a holdout set, and returns metrics on accuracy using that data. This is useful for validating that model will perform well on new data\n",
    "    - verbose: When set to True Keras will print a log during training. Useful for debugging.\n",
    "\n",
    "**What fitting does?**\n",
    "1. Applys backpropagation and gradient descent with data to update the weights\n",
    "    - note: Scaling data before fitting can ease optimization\n",
    "\n",
    "\n",
    "- Once we fit a model we need to evaluate it on new/unseen data.\n",
    "Even we use a validation set during training, we need to do a second check using a new set of data to make sure model perfoms as expected.\n",
    "To validate a model we use evaluate() method of a model and pass feature and target variable of new data.\n",
    "    - model.evaluate(test_feature, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('titanic.csv') # we will use titanic dataset for fitting the model\n",
    "\n",
    "# we will consider Age as feature and Survived as target\n",
    "feature=data['Age']\n",
    "target=data['Survived']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(feature,target, test_size=.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 498 samples, validate on 125 samples\n",
      "Epoch 1/1\n",
      "498/498 [==============================] - 0s 42us/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xeab4cc0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, batch_size=100, validation_split=.2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model:**\n",
    "\n",
    "We will give the model a new X matrix (also called feature test data), allow it to make predictions, and then compare to the known y variable (also called target data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 52us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: Advanced Deep Learning with Keras in Python by **Zachary Deane-Mayer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- How an activation function add non-linearity to a model?\n",
    "- How to decide how many nodes to add in a hidden layer?\n",
    "- How to decide how many hidden layers to add?\n",
    "- Can i use different number of nodes in respective layer or i need to keep it same for all layers?\n",
    "- How to know which function is processed or dropped at each node?\n",
    "- What are different optimizers and why adam is widely used? [and not GD, SGD]\n",
    "- How to choose batch size?\n",
    "- How to choose validation split?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
